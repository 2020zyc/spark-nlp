{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  0|The Da Vinci Code...|        1|\n",
      "|  1|this was the firs...|        1|\n",
      "|  2|i liked the Da Vi...|        1|\n",
      "|  3|i liked the Da Vi...|        1|\n",
      "|  4|I liked the Da Vi...|        1|\n",
      "|  5|that's not even a...|        1|\n",
      "|  6|I loved the Da Vi...|        1|\n",
      "|  7|i thought da vinc...|        1|\n",
      "|  8|The Da Vinci Code...|        1|\n",
      "|  9|I thought the Da ...|        1|\n",
      "| 10|The Da Vinci Code...|        1|\n",
      "| 11|The Da Vinci Code...|        1|\n",
      "| 12|then I turn on th...|        1|\n",
      "| 13|The Da Vinci Code...|        1|\n",
      "| 14|i love da vinci c...|        1|\n",
      "| 15|i loved da vinci ...|        1|\n",
      "| 16|TO NIGHT:: THE DA...|        1|\n",
      "| 17|THE DA VINCI CODE...|        1|\n",
      "| 18|Thing is, I enjoy...|        1|\n",
      "| 19|very da vinci cod...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7086"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the input data to be annotated\n",
    "home_path = \"file:///\" + os.getcwd() + \"/../../../../\"\n",
    "file_path = home_path + \\\n",
    "            \"spark-nlp-models/src/main/resources/datasets/training.parquet\"\n",
    "data = spark. \\\n",
    "       read. \\\n",
    "       parquet(file_path)\n",
    "data.cache()\n",
    "data.show()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "class SplitData:\n",
    "\n",
    "    @staticmethod\n",
    "    def randomSplit(per_train, per_test, data):\n",
    "        \"\"\"\n",
    "        This method splits randomly the data\n",
    "        :param per_train: percentaje of data to be used as training\n",
    "        :param per_test: percentaje of data to be used as testing\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        train_data, test_data = data.randomSplit([per_train, per_test], \n",
    "                                                 seed=1234)\n",
    "        print(f\"Training data. Total {train_data.count()}\")\n",
    "        print(f\"Testing data. Total {test_data.count()}\")\n",
    "        return train_data, test_data\n",
    "\n",
    "    @staticmethod\n",
    "    def filterData(data, label):\n",
    "        \"\"\"\n",
    "        This method filter the data into positive or negative\n",
    "        sentiment values\n",
    "        :param data: dataset to filter\n",
    "        :param label: sentiment label \"1\" for positive\n",
    "                      \"0\" for negative\n",
    "        \"\"\"\n",
    "        if label == \"1\":\n",
    "            label_desc = \"Positive\"\n",
    "        else:\n",
    "            label_desc = \"Negative\"\n",
    "        data = data.filter(F.col(\"sentiment\") == label)\n",
    "        print(f\"{label_desc} training data. Total {data.count()}\")\n",
    "        data.show(5)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def exportData(data, path, name, header=\"false\"):\n",
    "        \"\"\"\n",
    "        This method exports the data to disk\n",
    "        :param data: dataset to export\n",
    "        :param path: path where the file is being exported\n",
    "        :param name: name of the file\n",
    "        \"\"\"\n",
    "        data.write \\\n",
    "            .format(\"com.databricks.spark.csv\") \\\n",
    "            .option(\"header\", header) \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(path+name)\n",
    "        print(f\"Data {name} exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data. Total 5678\n",
      "Testing data. Total 1408\n",
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  3|i liked the Da Vi...|        1|\n",
      "|  4|I liked the Da Vi...|        1|\n",
      "|  5|that's not even a...|        1|\n",
      "|  6|I loved the Da Vi...|        1|\n",
      "|  7|i thought da vinc...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  0|The Da Vinci Code...|        1|\n",
      "|  1|this was the firs...|        1|\n",
      "|  2|i liked the Da Vi...|        1|\n",
      "| 13|The Da Vinci Code...|        1|\n",
      "| 26|I really like The...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 80% of the data for training and 20% for testing.\n",
    "train_data, test_data = SplitData.randomSplit(.8, .2, data)\n",
    "train_data.show(5)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the balance of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive training data. Total 3218\n",
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  3|i liked the Da Vi...|        1|\n",
      "|  4|I liked the Da Vi...|        1|\n",
      "|  5|that's not even a...|        1|\n",
      "|  6|I loved the Da Vi...|        1|\n",
      "|  7|i thought da vinc...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Negative training data. Total 2460\n",
      "+----+--------------------+---------+\n",
      "|  id|                text|sentiment|\n",
      "+----+--------------------+---------+\n",
      "|3995|da vinci code was...|        0|\n",
      "|3996|Then again, the D...|        0|\n",
      "|3999|God, Yahoo Games ...|        0|\n",
      "|4000|Da Vinci Code doe...|        0|\n",
      "|4001|And better...-We ...|        0|\n",
      "+----+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_positive = SplitData.filterData(train_data, \"1\")\n",
    "train_negative = SplitData.filterData(train_data, \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive training data. Total 777\n",
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  0|The Da Vinci Code...|        1|\n",
      "|  1|this was the firs...|        1|\n",
      "|  2|i liked the Da Vi...|        1|\n",
      "| 13|The Da Vinci Code...|        1|\n",
      "| 26|I really like The...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Negative training data. Total 631\n",
      "+----+--------------------+---------+\n",
      "|  id|                text|sentiment|\n",
      "+----+--------------------+---------+\n",
      "|3997|The Da Vinci Code...|        0|\n",
      "|3998|i thought the da ...|        0|\n",
      "|4005|And better..-We a...|        0|\n",
      "|4011|da vinci code suc...|        0|\n",
      "|4013|not sure if i alr...|        0|\n",
      "+----+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_positive = SplitData.filterData(test_data, \"1\")\n",
    "test_negative = SplitData.filterData(test_data, \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  3|i liked the Da Vi...|        1|\n",
      "|  4|I liked the Da Vi...|        1|\n",
      "|  5|that's not even a...|        1|\n",
      "|  6|I loved the Da Vi...|        1|\n",
      "|  7|i thought da vinc...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "2000\n",
      "+----+--------------------+---------+\n",
      "|  id|                text|sentiment|\n",
      "+----+--------------------+---------+\n",
      "|3995|da vinci code was...|        0|\n",
      "|3996|Then again, the D...|        0|\n",
      "|3999|God, Yahoo Games ...|        0|\n",
      "|4000|Da Vinci Code doe...|        0|\n",
      "|4001|And better...-We ...|        0|\n",
      "+----+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "train_positive = train_positive.limit(2000)\n",
    "train_positive.show(5)\n",
    "print(train_positive.count())\n",
    "train_negative = train_negative.limit(2000)\n",
    "train_negative.show(5)\n",
    "print(train_negative.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a balanced training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "+---+--------------------+---------+\n",
      "| id|                text|sentiment|\n",
      "+---+--------------------+---------+\n",
      "|  3|i liked the Da Vi...|        1|\n",
      "|  4|I liked the Da Vi...|        1|\n",
      "|  5|that's not even a...|        1|\n",
      "|  6|I loved the Da Vi...|        1|\n",
      "|  7|i thought da vinc...|        1|\n",
      "+---+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = train_positive.union(train_negative)\n",
    "print(train_data.count())\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data training_positive exported\n",
      "Data training_negative exported\n",
      "Data training_balanced exported\n",
      "Data testing exported\n"
     ]
    }
   ],
   "source": [
    "# Save data to disk\n",
    "file_path = home_path + \\\n",
    "            \"spark-nlp-models/src/main/resources/vivekn/\"\n",
    "train_positive = train_positive.select(F.col(\"text\"))\n",
    "SplitData.exportData(train_positive, file_path, \"training_positive\")\n",
    "\n",
    "train_negative = train_negative.select(F.col(\"text\"))\n",
    "SplitData.exportData(train_negative, file_path, \"training_negative\")\n",
    "\n",
    "file_path = home_path + \\\n",
    "            \"spark-nlp-models/src/main/resources/datasets/\"\n",
    "SplitData.exportData(train_data, file_path, \"training_balanced\", \"true\")\n",
    "SplitData.exportData(test_data, file_path, \"testing\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
