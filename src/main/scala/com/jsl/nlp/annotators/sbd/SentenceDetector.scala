package com.jsl.nlp.annotators.sbd

import com.jsl.nlp.annotators.param.AnnotatorParam
import com.jsl.nlp.annotators.sbd.pragmatic.SerializedSBDApproach
import com.jsl.nlp.{Annotation, Annotator, Document}
import org.apache.spark.ml.util.{DefaultParamsReadable, Identifiable}

/**
  * Created by Saif Addin on 5/5/2017.
  */

/**
  * Annotator that detects sentence boundaries using any provided approach
  * @param uid internal constructor requirement for serialization of params
  * @@ model: Model to use for boundaries detection
  */
class SentenceDetector(override val uid: String) extends Annotator {

  val model: AnnotatorParam[SBDApproach, SerializedSBDApproach] =
    new AnnotatorParam[SBDApproach, SerializedSBDApproach](this, "Sentence Detection model", "Approach to detect sentence boundaries")

  override val annotatorType: String = SentenceDetector.annotatorType

  override var requiredAnnotatorTypes: Array[String] = Array()

  def this() = this(Identifiable.randomUID(SentenceDetector.annotatorType))

  def getModel: SBDApproach = $(model)

  def setModel(targetModel: SBDApproach): this.type = set(model, targetModel)

  /**
    * Uses the model interface to prepare the context and extract the boundaries
    * @param document Usually refers to a container of raw text
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return One to many annotation relationship depending on how many sentences there are in the document
    */
  override def annotate(document: Document, annotations: Seq[Annotation]): Seq[Annotation] = {
    val sentences: Seq[Sentence] =
      getModel.extractBounds(document.text)
    sentences.map(sentence => Annotation(
      this.annotatorType,
      sentence.begin,
      sentence.end,
      Map[String, String](this.annotatorType -> sentence.content)
    ))
  }

}
object SentenceDetector extends DefaultParamsReadable[SentenceDetector] {
  val annotatorType = "sbd"
}